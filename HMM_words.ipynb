{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "#opening the tweet data files\n",
    "# with open('condensed_2011.json') as data_file:    \n",
    "#     data2011 = json.load(data_file)\n",
    "# with open('condensed_2012.json') as data_file:    \n",
    "#     data2012 = json.load(data_file)\n",
    "# with open('condensed_2013.json') as data_file:    \n",
    "#     data2013 = json.load(data_file)\n",
    "# with open('condensed_2014.json') as data_file:    \n",
    "#     data2014 = json.load(data_file)\n",
    "with open('condensed_2015.json') as data_file:    \n",
    "    data2015 = json.load(data_file)\n",
    "with open('condensed_2016.json') as data_file:    \n",
    "    data2016 = json.load(data_file)\n",
    "with open('condensed_2017.json') as data_file:    \n",
    "    data2017 = json.load(data_file)\n",
    "\n",
    "#storing the data in a single variable\n",
    "tweets=[]\n",
    "# for i in range(len(data2011)-1):\n",
    "#     tweets.append(data2011[i][\"text\"])\n",
    "# for i in range(len(data2012)-1):\n",
    "#     tweets.append(data2012[i][\"text\"])\n",
    "# for i in range(len(data2013)-1):\n",
    "#     tweets.append(data2013[i][\"text\"])\n",
    "# for i in range(len(data2014)-1):\n",
    "#     tweets.append(data2014[i][\"text\"])\n",
    "for i in range(len(data2015)-1):\n",
    "    tweets.append(data2015[i][\"text\"])\n",
    "for i in range(len(data2016)-1):\n",
    "    tweets.append(data2016[i][\"text\"])\n",
    "for i in range(len(data2017)-1):\n",
    "    tweets.append(data2017[i][\"text\"])   \n",
    "    \n",
    "tweet_words=[]\n",
    "for i in range(len(tweets)):\n",
    "    tweet_words.append(tweets[i].split(' '))  \n",
    "\n",
    "unique_dict=[]\n",
    "for i in range(len(tweet_words)-1):\n",
    "    for j in range(len(tweet_words[i])-1):\n",
    "        if tweet_words[i][j] not in unique_dict:\n",
    "            unique_dict.append(tweet_words[i][j])\n",
    "unique_dict.insert(0,' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths=np.zeros(len(tweet_words))\n",
    "for i in range(len(tweet_words)):\n",
    "    lengths[i]=len(tweet_words[i])\n",
    "ave_len=int(lengths.mean())\n",
    "\n",
    "# prob=np.zeros(len(unique_dict))\n",
    "# for i in range(len(tweet_words)-1):\n",
    "#     for k in range(len(tweet_words[i])):\n",
    "#         for j in range(len(unique_dict)-1):\n",
    "#             if tweet_words[i][k]==unique_dict[j]:\n",
    "#                 prob[j]=prob[j]+1\n",
    "# prob=prob/len(tweet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_map=range(1,np.size(unique_dict))\n",
    "\n",
    "index=0\n",
    "max_chars=140\n",
    "hid_states=np.zeros(int(np.size(tweet_words)*max(lengths)))\n",
    "for i in range(len(tweet_words)):\n",
    "    for k in range(len(tweet_words[i])):\n",
    "        for j in range(len(unique_dict)):\n",
    "            if tweet_words[i][k]==unique_dict[j]:\n",
    "                hid_states[index]=j\n",
    "                index=index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hid=np.zeros((np.size(tweet_words),int(max(lengths))))\n",
    "for i in range(np.size(tweet_words)-1):\n",
    "    for j in range(len(tweet_words[i])-1):\n",
    "        if len(tweet_words[i])<140:\n",
    "            hid[i,j]=hid_states[i+i*j]\n",
    "\n",
    "hid=hid[1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from hmmlearn import base\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "model=hmm.GaussianHMM(n_components=100,n_iter=5);\n",
    "model.fit(hid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['millions',\n",
       " 'VOTE',\n",
       " 'out',\n",
       " 'forget',\n",
       " '#MakeAmericaGreatAgain',\n",
       " '&amp;',\n",
       " 'he',\n",
       " '&amp;',\n",
       " '@DonaldJTrumpJr!',\n",
       " 'get',\n",
       " 'believe',\n",
       " 'out',\n",
       " '&amp;',\n",
       " 'believe',\n",
       " '#MakeAmericaGreatAgain',\n",
       " 'out',\n",
       " 'forget',\n",
       " '&amp;',\n",
       " '&amp;']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,state_seq=model.sample(n_samples=np.random.randint(0,max(lengths)));\n",
    "seq=[]\n",
    "for i in range(len(state_seq)):\n",
    "    seq.append(unique_dict[state_seq[i]])\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Independent',\n",
       " 'husband,',\n",
       " '@DavidMuir',\n",
       " 'suggests',\n",
       " 'AMERICA',\n",
       " '\"Thereâ€™s',\n",
       " '.@jessebwatters',\n",
       " '\"Trump\"',\n",
       " 'weakening',\n",
       " 'provides',\n",
       " 'doing',\n",
       " 'reference',\n",
       " 'bully',\n",
       " 'Chevy',\n",
       " 'Coming',\n",
       " 'my',\n",
       " 'winning',\n",
       " 'Chair.',\n",
       " 'Vegas,',\n",
       " 'ground',\n",
       " '\"@BentleyforTrump:',\n",
       " 'his',\n",
       " 'Donald.',\n",
       " 'landing',\n",
       " 'Nevada']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_seq=model._generate_sample_from_state(50);\n",
    "seq=[]\n",
    "for i in range(len(state_seq)):\n",
    "    if(unique_dict[int(state_seq[i])]!=' '):\n",
    "        seq.append(unique_dict[int(state_seq[i])])\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
